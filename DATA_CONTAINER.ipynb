{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784b332-0bc4-43d9-93b8-826646e8824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run PATTERN_OBSERVER.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9f0a-86c8-4dc2-8e58-751ba36f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7fdb8-e811-4706-9bb5-c3fd0bde95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA_CONTAINER(IObserver,ISubject):\n",
    "    ####################################\n",
    "    # static\n",
    "    ####################################\n",
    "    # standardized file names\n",
    "    BTPATHTUPLE      = namedtuple('BTPATHTUPLE',['backtest_name','subdir','filename'])\n",
    "    _dev             = BTPATHTUPLE('./','./',None)\n",
    "    _daily           = BTPATHTUPLE(None,'./daily','summary_YYYYMMDD')\n",
    "    _extraday        = BTPATHTUPLE(None,'./extraday','BOOK_YYYYMMDD')\n",
    "    _intraday        = BTPATHTUPLE(None,'./intraday','BOOK_YYYYMMDD')\n",
    "    _factor          = BTPATHTUPLE(None,'./factor','BOOK_YYYYMMDD')\n",
    "\n",
    "    ####################################\n",
    "    # constructor\n",
    "    ####################################\n",
    "    def __init__(self,\n",
    "        name                  : str = 'DATA_CONTAINER',\n",
    "        datatype              : str = 'dev',\n",
    "        applied_backtest_path : str = r'C:\\Users\\ahkar\\OneDrive\\Documents\\Data\\B3',\n",
    "        applied_date_from=None,\n",
    "        applied_date_to=None,\n",
    "        applied_return_type   : str = None,\n",
    "        selected_backtests=None,\n",
    "        selected_books=None\n",
    "        ):\n",
    "        if selected_backtests==None:\n",
    "            selected_backtests={\n",
    "                'AZUL4.SA': Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/AZUL4.SA.csv'),\n",
    "                'EMBR3.SA': Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/EMBR3.SA.csv')\n",
    "            }\n",
    "        if datatype==None:\n",
    "            datatype={\n",
    "                'Trading': 'Trading',\n",
    "                'Quote': 'Quote',\n",
    "                'MM2': 'MM2',\n",
    "                'Hedge': 'Hedge',\n",
    "                'Hit': 'Hit'\n",
    "            }\n",
    "        \n",
    "        self.name=name\n",
    "        self.reference={\n",
    "            'applied_backtest_path':applied_backtest_path,        # observes changes to `SETTINGS|backtest_path`\n",
    "            'applied_date_from':applied_date_from,                # observes changes to `SETTINGS|date_from`\n",
    "            'applied_date_to':applied_date_to,                    # observes changes to `SETTINGS|date_to`\n",
    "            'applied_return_type':applied_return_type,            # observes changes to `SETTINGS|return_type`\n",
    "            'selected_backtests':selected_backtests,              # observes changes to `BACKTEST_VIEWER|selected_backtests`\n",
    "            'selected_books':selected_books,                      # observes changes to `BACKTEST_VIEWER|selected_books`\n",
    "        }\n",
    "            \n",
    "        self.data_dico={} # container for all data\n",
    "        self._observers=set() # for observer pattern\n",
    "        self._logging() # show internals\n",
    "        '''\n",
    "        on backtest_widget apply button\n",
    "            update DATA_CONTAINER.data dictionary\n",
    "            update DATA_CONTAINER.selected_backtests\n",
    "            \n",
    "        on book_widget apply button\n",
    "            update DATA_CONTAINER.selected_books\n",
    "            \n",
    "        post updating, update all visible plots\n",
    "        '''\n",
    "        \n",
    "    ####################################\n",
    "    # observer pattern\n",
    "    ####################################\n",
    "    # subject\n",
    "    def attach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'OBSERVES',self.name)\n",
    "        self._observers.add(observer)\n",
    "        \n",
    "    def detach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'STOPS OBSERVING',self.name)\n",
    "        self._observers.remove(observer)\n",
    "        \n",
    "    def notify(self,info) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'NOTIFIES',len(self._observers),'OBSERVERS')\n",
    "        \n",
    "        # print receivers\n",
    "        for observer in self._observers:\n",
    "            print('OBSERVER PATTERN',':',self.name,'NOTIFIES',observer.name)\n",
    "            observer.react(self.name,info)\n",
    "\n",
    "    # observer\n",
    "    def react(self,\n",
    "        subject_name : str,\n",
    "        subject_info : object\n",
    "        ) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_name',subject_name)\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_info',subject_info)\n",
    "\n",
    "        # SETTINGS changed\n",
    "        if subject_name=='SETTINGS':\n",
    "            \n",
    "            if 'force_reload' in subject_info:\n",
    "                # told by SETTINGS to reload all backtests\n",
    "                self._data_dico.clear() # empty\n",
    "                self._populate_data_dico() # repopulate\n",
    "            else:\n",
    "                if Path(self.reference['applied_backtest_path'])!=Path(subject_info['backtest_path']):\n",
    "                    print('OBSERVER PATTERN',':',self.name,'clear dico')\n",
    "                    self.data_dico.clear() # empty data_dico if filepath changed\n",
    "\n",
    "                # update\n",
    "                self.reference['applied_backtest_path']=subject_info['backtest_path']\n",
    "                self.reference['applied_date_from']=subject_info['date_from']\n",
    "                self.reference['applied_date_to']=subject_info['date_to']\n",
    "                self.reference['applied_return_type']=subject_info['return_type']\n",
    "        \n",
    "        # BACKTEST_SELECTOR changed\n",
    "        if subject_name=='BACKTEST_SELECTOR':\n",
    "            self.reference['selected_backtests']=subject_info\n",
    "            self._populate_data_dico()\n",
    "\n",
    "        # BOOK_SELECTOR changed\n",
    "        if subject_name=='BOOK_SELECTOR':\n",
    "            self.reference['selected_books']=[k for k,v in subject_info.items() if v] # return checked values\n",
    "\n",
    "        # logging\n",
    "        self._logging()\n",
    "    \n",
    "    def _populate_data_dico(self) -> None:\n",
    "        # update data_dico\n",
    "        for (option_name,option_path),checked in self.reference['selected_backtests'].items():\n",
    "            if checked:\n",
    "                self._add_key(option_name,option_path) # make sure present\n",
    "            else:\n",
    "                self._remove_key(option_name,option_path) # make sure not present\n",
    "\n",
    "    def _logging(self):\n",
    "        print(self.name,':','REFERENCE',':','DATA_DICO SIZE =',len(self.data_dico))\n",
    "        for k,v in self.reference.items():\n",
    "            print(self.name,':','REFERENCE',':',k,':',v)\n",
    "\n",
    "    ####################################\n",
    "    # own stuff\n",
    "    ####################################\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    print(d.get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),datatype='dev'))\n",
    "    print(d.get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),datatype='daily'))\n",
    "    print(d.get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),datatype='intraday'))\n",
    "    print(d.get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),datatype='extraday'))\n",
    "    print(d.get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),datatype='factor'))\n",
    "    '''\n",
    "    def get_filepath(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        datatype : str ='dev',\n",
    "        ) -> Path :\n",
    "        BackestPathTuple=eval('DATA_CONTAINER.'+datatype+'()') # get BTPATHTUPLE\n",
    "        tup=[option_path.parent]+list(BackestPathTuple) # build tuple\n",
    "        tup=[option_name if x==None else x for x in tup] # overwrite None in BackestPathTuple with backtest_name\n",
    "        filepath=reduce(lambda x,y:x/y,tup) # combine into single Path object\n",
    "        filepath=Path(str(filepath) + '.csv') # append .csv suffix\n",
    "        return filepath\n",
    "        \n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    d._add_key('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    '''\n",
    "    \n",
    "    '''make sure data is populated'''\n",
    "    def _add_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        datatype : str ='dev',\n",
    "        ) -> None :\n",
    "        if not option_name in self.data_dico:\n",
    "            print(self.name,':','KEYS =',len(self.data_dico),':',option_name,'ADD')\n",
    "            self.data_dico[option_name]=pd.read_csv(self.get_filepath(option_name,option_path,datatype))\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self.data_dico),':',option_name,'pass (no add)')\n",
    "            pass\n",
    "    \n",
    "    '''make sure data removed from data_dico'''\n",
    "    def _remove_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        ) -> None :\n",
    "        if option_name in self.data_dico:\n",
    "            print(self.name,':','KEYS =',len(self.data_dico),':',option_name,'REMOVE')\n",
    "            del self.data_dico[option_name] # remove from dico\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self.data_dico),':',option_name,'pass (no remove)')\n",
    "            pass\n",
    "\n",
    "    @classmethod\n",
    "    def dev(self) -> BTPATHTUPLE :\n",
    "        return DATA_CONTAINER._dev\n",
    "    \n",
    "    @classmethod\n",
    "    def daily(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "             extraday summary --> macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/daily/summary_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            book|pnl|stock volume|future volume|fees\n",
    "            All|.|.|.|.\n",
    "            Trading|.|.|.|.\n",
    "            Quote|.|.|.|.\n",
    "            Hedge|.|.|.|.\n",
    "\n",
    "        used to compute summary for entire backtest\n",
    "            book|return bps|sharpe|daily pnl|daily stock volume|daily future volume|fee bps\n",
    "            All|.|.|.|.|.|.\n",
    "            Trading|.|.|.|.|.|.\n",
    "            Quote|.|.|.|.|.|.\n",
    "            Hedge|.|.|.|.|.|.\n",
    "        '''\n",
    "        return DATA_CONTAINER._daily\n",
    "    \n",
    "    @classmethod\n",
    "    def extraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday behavioural analysis --> customised macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            EOD|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._extraday\n",
    "    \n",
    "    @classmethod\n",
    "    def intraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            intraday behavioural analysis --> customised macro intraday overview\n",
    "\n",
    "        dump frequency\n",
    "            n-minutely snapshots throughout the day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/intraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            10:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            10:01:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            ...\n",
    "            16:59:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            17:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._intraday\n",
    "\n",
    "    @classmethod\n",
    "    def factor(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday factor analysis --> customised macro factor analysis\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            dump on all symbols\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            Symbol|PnlTotal|PnlJour|PnlVeille|ExecNom|MedLongNom|MaxLongLongNom|MedOpenBidNom|MedOpenAskNom|...\n",
    "            sym_0|\n",
    "            sym_1|\n",
    "            ...\n",
    "            sym_n|\n",
    "        '''\n",
    "        return DATA_CONTAINER._factor\n",
    "    \n",
    "        '''\n",
    "    \n",
    "            self.raw_data=\n",
    "        self.filtered_data=self.apply_date_filters()\n",
    "        \n",
    "\n",
    "    def apply_date_filters(self):\n",
    "        # check date validity\n",
    "        \n",
    "        # remember filter dates applied\n",
    "        min_date=self.settings['date_from'].value\n",
    "        max_date=self.settings['date_to'].value\n",
    "\n",
    "        # apply date filter\n",
    "        if min_date==None and max_date==None:\n",
    "            print('no filter')\n",
    "            self.filtered_data=self.raw_data\n",
    "        elif min_date!=None and max_date==None:\n",
    "            print('filter min_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date>=min_date]\n",
    "        elif min_date==None and max_date!=None:\n",
    "            print('filter max_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date<=max_date]\n",
    "        else:\n",
    "            print('filter both')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date.between(min_date,max_date)]\n",
    "            \n",
    "        # debugging\n",
    "        print(min_date)\n",
    "        print(max_date)\n",
    "        print(self.raw_data.shape)\n",
    "        print(self.filtered_data.shape)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22478bbe-34a0-4a06-8344-dae272a8a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "d=DATA_CONTAINER()\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59847276-62af-41fe-a852-801c851fa69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DATA_CONTAINER.daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f07ae02-f10e-4319-9bb9-a44c298402e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DATA_CONTAINER.extraday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2cb7d-5f47-4fed-9aa6-000790e78067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DATA_CONTAINER.intraday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ec483-2a39-4e98-b398-4a56a7d4fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(DATA_CONTAINER.factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
