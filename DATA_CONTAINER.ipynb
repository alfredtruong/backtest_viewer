{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d152e69-dfc3-42ea-bc8e-76b061f1c3f8",
   "metadata": {},
   "source": [
    "### module import protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa010cb6-4cfa-4737-b4f5-3334e74172a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_DATA_CONTAINER') == None:\n",
    "    display('LOADED_DATA_CONTAINER')\n",
    "    LOADED_DATA_CONTAINER=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74f8f8-5645-44f0-a8f7-11136579863c",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993c62-1f16-4135-8bd1-597b0d82ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_ANNOTATIONS') == None:\n",
    "    %run ANNOTATIONS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784b332-0bc4-43d9-93b8-826646e8824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_PATTERN_OBSERVER') == None:\n",
    "    %run PATTERN_OBSERVER.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c24fd-ab9c-48d3-9f6b-03ece7199868",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9f0a-86c8-4dc2-8e58-751ba36f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d631a-6b89-4427-8208-115575a98ae5",
   "metadata": {},
   "source": [
    "### begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5b55e-e54b-4621-a0e4-253c1fed8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SUBJECT\n",
    "- VIEWING_TABS observes DATA_CONTAINER to populate itself\n",
    "\n",
    "OBSERVER\n",
    "- DATA_CONTAINER observes SETTINGS for repopulation purposes\n",
    "- DATA_CONTAINER observes BACKTEST_SELECTOR for population purposes\n",
    "- DATA_CONTAINER observes BOOK_SELECTOR for population purposes\n",
    "'''\n",
    "class DATA_CONTAINER(IObserver,ISubject):\n",
    "    ####################################\n",
    "    # static\n",
    "    ####################################\n",
    "    # standardized file names\n",
    "    BTPATHTUPLE      = namedtuple('BTPATHTUPLE',['backtest_name','subdir','filename'])\n",
    "    _dev             = BTPATHTUPLE('./','./',None)\n",
    "    _daily           = BTPATHTUPLE(None,'./daily','summary_YYYYMMDD')\n",
    "    _extraday        = BTPATHTUPLE(None,'./extraday','BOOK_YYYYMMDD')\n",
    "    _intraday        = BTPATHTUPLE(None,'./intraday','BOOK_YYYYMMDD')\n",
    "    _factor          = BTPATHTUPLE(None,'./factor','BOOK_YYYYMMDD')\n",
    "\n",
    "    ####################################\n",
    "    # constructor\n",
    "    ####################################\n",
    "    def __init__(self,\n",
    "        name                  : str = 'DATA_CONTAINER',\n",
    "        applied_backtest_path : str = r'C:\\Users\\ahkar\\OneDrive\\Documents\\Data\\B3',\n",
    "        applied_view_type     : str = None,\n",
    "        applied_plot_type     : str = None,\n",
    "        applied_return_type   : str = None,\n",
    "        applied_date_from           = None,\n",
    "        applied_date_to             = None,\n",
    "        selected_backtests          = None,\n",
    "        selected_books              = None\n",
    "        ):\n",
    "        self.name                   = name\n",
    "        self._applied_backtest_path = applied_backtest_path\n",
    "        self._applied_view_type     = applied_view_type\n",
    "        self._applied_plot_type     = applied_plot_type\n",
    "        self._applied_return_type   = applied_return_type\n",
    "        self._selected_backtests    = selected_backtests if selected_backtests != None else self._populate_selected_backtests()\n",
    "        self._selected_books        = selected_books if selected_books != None else self._populate_selected_books()\n",
    "        self._data_dico             = {}\n",
    "                \n",
    "        # for observer pattern\n",
    "        self._observers             = []\n",
    "        self.reference              = {\n",
    "            'applied_view_type'     : applied_view_type,\n",
    "            'applied_plot_type'     : applied_plot_type,\n",
    "            'applied_return_type'   : applied_return_type,\n",
    "            'applied_date_from'     : applied_date_from,\n",
    "            'applied_date_to'       : applied_date_to,\n",
    "            'applied_backtest_path' : applied_backtest_path,\n",
    "            'df'                    : pd.DataFrame(),\n",
    "        }\n",
    "            \n",
    "        self._logging() # show internals\n",
    "        \n",
    "    ####################################\n",
    "    # populate defaults\n",
    "    ####################################\n",
    "    def _populate_selected_backtests(self) -> OPTIONID_VALUES :\n",
    "        return {\n",
    "            ('AZUL4.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/AZUL4.SA.csv')) : True,\n",
    "            ('EMBR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/EMBR3.SA.csv')) : True,\n",
    "            ('ECOR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/ECOR3.SA.csv')) : False,\n",
    "        }\n",
    "\n",
    "    def _populate_selected_books(self) -> OPTIONID_VALUES :\n",
    "        return {\n",
    "            ('Trading','Trading') : True,\n",
    "            ('Quote','Quote')     : True,\n",
    "            ('MM2','MM2')         : True,\n",
    "            ('Hedge','Hedge')     : True,\n",
    "            ('Hit','Hit')         : False,\n",
    "        }\n",
    "\n",
    "    ####################################\n",
    "    # observer pattern\n",
    "    ####################################\n",
    "    # subject\n",
    "    def attach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'OBSERVES',self.name)\n",
    "        self._observers.append(observer)\n",
    "        \n",
    "    def detach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'STOPS OBSERVING',self.name)\n",
    "        self._observers.remove(observer)\n",
    "        \n",
    "    def notify(self,info) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'NOTIFIES',len(self._observers),'OBSERVERS')\n",
    "        \n",
    "        # print receivers\n",
    "        for observer in self._observers:\n",
    "            print('OBSERVER PATTERN',':',self.name,'NOTIFIES',observer.name)\n",
    "            observer.react(self.name,info)\n",
    "\n",
    "    # observer\n",
    "    def react(self,\n",
    "        subject_name : str,\n",
    "        subject_info : object\n",
    "        ) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_name',subject_name)\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_info',subject_info.keys())\n",
    "\n",
    "        # SETTINGS changed\n",
    "        if subject_name == 'SETTINGS':\n",
    "            if 'reload_data' in subject_info:\n",
    "                # told by SETTINGS to reload all backtests\n",
    "                print(self.name,':','reload_data')\n",
    "                \n",
    "                self._data_dico.clear() # empty data_dico and reload\n",
    "                self._logging() # show internals\n",
    "\n",
    "                self.reference['df']                    = self._build_df(self.reference['applied_view_type']) # updates self._data_dico as well\n",
    "            else:\n",
    "                print(self.name,':','update settings')\n",
    "                \n",
    "                '''\n",
    "                this block is probably redundant\n",
    "                # empty data_dico if SETTINGS filepath OR view_type changed\n",
    "                if (\n",
    "                    self.reference['applied_backtest_path'] != Path(subject_info['backtest_path']) or # path changed\n",
    "                    self.reference['applied_view_type']     != subject_info['view_type']              # view type changed\n",
    "                ):\n",
    "                    print('OBSERVER PATTERN',':',self.name,'clear dico')\n",
    "                    self._data_dico.clear() # TODO , dont clear dico, ensure self._selected_backtests is emptied instead\n",
    "                this block is probably redundant\n",
    "                '''\n",
    "                \n",
    "                # update\n",
    "                self.reference['applied_view_type']     = subject_info['view_type']\n",
    "                self.reference['applied_plot_type']     = subject_info['plot_type']\n",
    "                self.reference['applied_return_type']   = subject_info['return_type']\n",
    "                self.reference['applied_date_from']     = subject_info['date_from']\n",
    "                self.reference['applied_date_to']       = subject_info['date_to']\n",
    "                self.reference['applied_backtest_path'] = subject_info['backtest_path']\n",
    "                self.reference['df']                    = self._build_df(self.reference['applied_view_type'])\n",
    "        \n",
    "        # BACKTEST_SELECTOR changed\n",
    "        if subject_name == 'BACKTEST_SELECTOR':\n",
    "            self._selected_backtests                    = subject_info\n",
    "            self.reference['df']                        = self._build_df(self.reference['applied_view_type'])\n",
    "\n",
    "        # BOOK_SELECTOR changed\n",
    "        if subject_name == 'BOOK_SELECTOR':\n",
    "            self._selected_books                        = subject_info\n",
    "\n",
    "        # BACKTEST_VIEWER changed\n",
    "        if subject_name == 'BACKTEST_VIEWER':\n",
    "            print(self.name,'BACKTEST_VIEWER force replot via DATA_CONTAINER')\n",
    "            \n",
    "        # logging\n",
    "        self._logging()\n",
    "        \n",
    "        # notify\n",
    "        self.notify(self.reference)\n",
    "    \n",
    "    ####################################\n",
    "    # functions\n",
    "    ####################################\n",
    "    def _extraday_set_index(self,df : pd.DataFrame) -> pd.DataFrame :\n",
    "        df.timestamp = pd.to_datetime(df.timestamp)\n",
    "        return df.set_index('timestamp')\n",
    "\n",
    "    def _build_df(self,view_type : str) -> pd.DataFrame : # TODO, this needs to depend on `view_type`\n",
    "        print(self.name,':','_build_df','view_type =',view_type)\n",
    "\n",
    "        ##################\n",
    "        # add / remove as per checks\n",
    "        ##################\n",
    "        for (option_name,option_path),checked in self._selected_backtests.items():\n",
    "            if checked:\n",
    "                self._data_dico_add_key(option_name,option_path) # make sure present\n",
    "            else:\n",
    "                self._data_dico_remove_key(option_name,option_path) # make sure not present\n",
    "\n",
    "        ##################\n",
    "        # remove options no longer in range from self._data_dico\n",
    "        ##################\n",
    "        remove=[]\n",
    "        for (option_name,option_path) in self._data_dico.keys():\n",
    "            if not (option_name,option_path) in self._selected_backtests.keys():\n",
    "                remove.append((option_name,option_path))\n",
    "        \n",
    "        for (option_name,option_path) in remove:\n",
    "            self._data_dico_remove_key(option_name,option_path)\n",
    "        \n",
    "        ##################\n",
    "        # bail if empty dico\n",
    "        ##################\n",
    "        if not self._data_dico:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        ##################\n",
    "        # build df (dico not empty)\n",
    "        ##################\n",
    "        # flatten\n",
    "        df = pd.concat(\n",
    "            map(self._extraday_set_index,self._data_dico.values()),\n",
    "            keys=[option_name for (option_name,option_path) in self._data_dico.keys()],\n",
    "            names=['sym']\n",
    "        )\n",
    "\n",
    "        # reorder\n",
    "        df = df.reorder_levels([1,0])\n",
    "        \n",
    "        ##################\n",
    "        # apply filters\n",
    "        ##################\n",
    "        if self.reference['applied_view_type'] == 'Extraday':\n",
    "            # apply lower date filter\n",
    "            if not self.reference['applied_date_from'] is None:\n",
    "                df = df[df.index.get_level_values('timestamp').date >= self.reference['applied_date_from']]\n",
    "            # apply upper date filter\n",
    "            if not self.reference['applied_date_to'] is None:\n",
    "                df = df[df.index.get_level_values('timestamp').date <= self.reference['applied_date_to']]\n",
    "        \n",
    "        if self.reference['applied_view_type'] == 'Intraday':\n",
    "            # apply lower time filter\n",
    "            if not self.reference['applied_time_from'] is None:\n",
    "                df = df[df.index.get_level_values('timestamp').time >= self.reference['applied_time_from']]\n",
    "            # apply upper time filter\n",
    "            if not self.reference['applied_time_to'] is None:\n",
    "                df = df[df.index.get_level_values('timestamp').time <= self.reference['applied_time_to']]\n",
    "\n",
    "        ##################\n",
    "        # return\n",
    "        ##################\n",
    "        return df \n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    d._data_dico_add_key('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    '''\n",
    "    def _data_dico_add_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type   : str = 'dev',\n",
    "        ) -> None :\n",
    "        '''make sure data is populated'''\n",
    "        if not (option_name,option_path) in self._data_dico:\n",
    "            self._data_dico[(option_name,option_path)]=pd.read_csv(self._get_filepath(option_name,option_path,view_type))\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',(option_name,option_path),'ADD')\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',(option_name,option_path),'pass (no add)')\n",
    "            pass\n",
    "    \n",
    "    def _data_dico_remove_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        ) -> None :\n",
    "        '''make sure data removed from data_dico'''\n",
    "        if (option_name,option_path) in self._data_dico:\n",
    "            del self._data_dico[(option_name,option_path)] # remove from dico\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',(option_name,option_path),'REMOVE')\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',(option_name,option_path),'pass (no remove)')\n",
    "            pass\n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='dev'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='daily'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='intraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='extraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='factor'))\n",
    "    '''\n",
    "    def _get_filepath(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type   : str = 'dev',\n",
    "        ) -> Path :\n",
    "        # build\n",
    "        BackestPathTuple = eval('DATA_CONTAINER.'+view_type+'()')       # get BTPATHTUPLE\n",
    "        tup              = [option_path.parent]+list(BackestPathTuple)  # build tuple\n",
    "        tup              = [option_name if x==None else x for x in tup] # overwrite None in BackestPathTuple with backtest_name\n",
    "        filepath         = reduce(lambda x,y:x/y,tup)                   # combine into single Path object\n",
    "        filepath         = Path(str(filepath) + '.csv')                 # append .csv suffix\n",
    "        \n",
    "        # return\n",
    "        return filepath\n",
    "        \n",
    "    def _logging(self):\n",
    "        print(self.name,':','REFERENCE',':','DATA_DICO SIZE =',len(self._data_dico))\n",
    "        for k,v in self.reference.items():\n",
    "            if k != 'df':\n",
    "                print(self.name,':','REFERENCE',':',k,':',v)\n",
    "            else:\n",
    "                print(self.name,':','REFERENCE',':',k,':',len(v))\n",
    "\n",
    "    @classmethod\n",
    "    def dev(self) -> BTPATHTUPLE :\n",
    "        return DATA_CONTAINER._dev\n",
    "    \n",
    "    @classmethod\n",
    "    def daily(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "             extraday summary --> macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/daily/summary_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            book|pnl|stock volume|future volume|fees\n",
    "            All|.|.|.|.\n",
    "            Trading|.|.|.|.\n",
    "            Quote|.|.|.|.\n",
    "            Hedge|.|.|.|.\n",
    "\n",
    "        used to compute summary for entire backtest\n",
    "            book|return bps|sharpe|daily pnl|daily stock volume|daily future volume|fee bps\n",
    "            All|.|.|.|.|.|.\n",
    "            Trading|.|.|.|.|.|.\n",
    "            Quote|.|.|.|.|.|.\n",
    "            Hedge|.|.|.|.|.|.\n",
    "        '''\n",
    "        return DATA_CONTAINER._daily\n",
    "    \n",
    "    @classmethod\n",
    "    def extraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday behavioural analysis --> customised macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            EOD|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._extraday\n",
    "    \n",
    "    @classmethod\n",
    "    def intraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            intraday behavioural analysis --> customised macro intraday overview\n",
    "\n",
    "        dump frequency\n",
    "            n-minutely snapshots throughout the day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/intraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            10:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            10:01:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            ...\n",
    "            16:59:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            17:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._intraday\n",
    "\n",
    "    @classmethod\n",
    "    def factor(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday factor analysis --> customised macro factor analysis\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            dump on all symbols\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            Symbol|PnlTotal|PnlJour|PnlVeille|ExecNom|MedLongNom|MaxLongLongNom|MedOpenBidNom|MedOpenAskNom|...\n",
    "            sym_0|\n",
    "            sym_1|\n",
    "            ...\n",
    "            sym_n|\n",
    "        '''\n",
    "        return DATA_CONTAINER._factor\n",
    "    \n",
    "        '''\n",
    "    \n",
    "            self.raw_data=\n",
    "        self.filtered_data=self.apply_date_filters()\n",
    "        \n",
    "\n",
    "    def apply_date_filters(self):\n",
    "        # check date validity\n",
    "        \n",
    "        # remember filter dates applied\n",
    "        min_date=self.settings['date_from'].value\n",
    "        max_date=self.settings['date_to'].value\n",
    "\n",
    "        # apply date filter\n",
    "        if min_date==None and max_date==None:\n",
    "            print('no filter')\n",
    "            self.filtered_data=self.raw_data\n",
    "        elif min_date!=None and max_date==None:\n",
    "            print('filter min_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date>=min_date]\n",
    "        elif min_date==None and max_date!=None:\n",
    "            print('filter max_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date<=max_date]\n",
    "        else:\n",
    "            print('filter both')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date.between(min_date,max_date)]\n",
    "            \n",
    "        # debugging\n",
    "        print(min_date)\n",
    "        print(max_date)\n",
    "        print(self.raw_data.shape)\n",
    "        print(self.filtered_data.shape)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada73279-b81a-444b-a295-1ebd0ac3cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipydatetime\n",
    "import ipywidgets\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e67902-fcce-4306-a579-655b9f8c8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_picker = ipydatetime.TimePicker()\n",
    "time_picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2b848-ab7a-48ed-a22e-55ea4c283f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __file__ exists if notebook called with %run\n",
    "# e.g. only do example if called directly\n",
    "try:\n",
    "    __file__\n",
    "except NameError:\n",
    "    # example\n",
    "    a=DATA_CONTAINER()\n",
    "    display(dir(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2b7c2-d297-4844-98a9-877d7a65cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "help(DATA_CONTAINER.daily)\n",
    "\n",
    "help(DATA_CONTAINER.extraday)\n",
    "\n",
    "help(DATA_CONTAINER.intraday)\n",
    "\n",
    "help(DATA_CONTAINER.factor)\n",
    "'''\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
