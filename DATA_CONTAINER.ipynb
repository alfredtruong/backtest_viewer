{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993c62-1f16-4135-8bd1-597b0d82ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ANNOTATIONS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784b332-0bc4-43d9-93b8-826646e8824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run PATTERN_OBSERVER.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9f0a-86c8-4dc2-8e58-751ba36f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7fdb8-e811-4706-9bb5-c3fd0bde95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA_CONTAINER(IObserver,ISubject):\n",
    "    ####################################\n",
    "    # static\n",
    "    ####################################\n",
    "    # standardized file names\n",
    "    BTPATHTUPLE      = namedtuple('BTPATHTUPLE',['backtest_name','subdir','filename'])\n",
    "    _dev             = BTPATHTUPLE('./','./',None)\n",
    "    _daily           = BTPATHTUPLE(None,'./daily','summary_YYYYMMDD')\n",
    "    _extraday        = BTPATHTUPLE(None,'./extraday','BOOK_YYYYMMDD')\n",
    "    _intraday        = BTPATHTUPLE(None,'./intraday','BOOK_YYYYMMDD')\n",
    "    _factor          = BTPATHTUPLE(None,'./factor','BOOK_YYYYMMDD')\n",
    "\n",
    "    ####################################\n",
    "    # constructor\n",
    "    ####################################\n",
    "    def __init__(self,\n",
    "        name                  : str = 'DATA_CONTAINER',\n",
    "        applied_backtest_path : str = r'C:\\Users\\ahkar\\OneDrive\\Documents\\Data\\B3',\n",
    "        applied_view_type     : str = None,\n",
    "        applied_return_type   : str = None,\n",
    "        applied_date_from           = None,\n",
    "        applied_date_to             = None,\n",
    "        selected_backtests          = None,\n",
    "        selected_books              = None\n",
    "        ):\n",
    "        self.name=name\n",
    "        self._applied_backtest_path=Path(applied_backtest_path)\n",
    "        self._applied_view_type=applied_view_type\n",
    "        self._selected_backtests=selected_backtests if selected_backtests!=None else self._populate_defaults_selected_backtests()\n",
    "        self._selected_books=selected_books if selected_books!=None else self._populate_defaults_selected_books()\n",
    "        self._data_dico={}\n",
    "                \n",
    "        self.reference={\n",
    "            'dataframe':pd.DataFrame(),\n",
    "            'applied_return_type':applied_return_type,\n",
    "            'applied_date_from':applied_date_from,\n",
    "            'applied_date_to':applied_date_to,\n",
    "        }\n",
    "            \n",
    "        self._observers=set() # for observer pattern\n",
    "        self._logging() # show internals\n",
    "        \n",
    "    ####################################\n",
    "    # populate defaults\n",
    "    ####################################\n",
    "    def _populate_defaults_selected_backtests(self) -> OPTIONID_VALUES :\n",
    "        return {\n",
    "            ('AZUL4.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/AZUL4.SA.csv')) : True,\n",
    "            ('EMBR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/EMBR3.SA.csv')) : True,\n",
    "            ('ECOR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/ECOR3.SA.csv')) : False,\n",
    "        }\n",
    "\n",
    "    def _populate_defaults_selected_books(self) -> OPTIONID_VALUES :\n",
    "        return {\n",
    "            ('Trading','Trading') : True,\n",
    "            ('Quote','Quote') : True,\n",
    "            ('MM2','MM2') : True,\n",
    "            ('Hedge','Hedge') : True,\n",
    "            ('Hit','Hit') : False,\n",
    "        }\n",
    "\n",
    "    ####################################\n",
    "    # observer pattern\n",
    "    ####################################\n",
    "    # subject\n",
    "    def attach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'OBSERVES',self.name)\n",
    "        self._observers.add(observer)\n",
    "        \n",
    "    def detach(self,observer : IObserver) -> None :\n",
    "        print('OBSERVER PATTERN',':',observer.name,'STOPS OBSERVING',self.name)\n",
    "        self._observers.remove(observer)\n",
    "        \n",
    "    def notify(self,info) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'NOTIFIES',len(self._observers),'OBSERVERS')\n",
    "        \n",
    "        # print receivers\n",
    "        for observer in self._observers:\n",
    "            print('OBSERVER PATTERN',':',self.name,'NOTIFIES',observer.name)\n",
    "            observer.react(self.name,info)\n",
    "\n",
    "    # observer\n",
    "    def react(self,\n",
    "        subject_name : str,\n",
    "        subject_info : object\n",
    "        ) -> None :\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_name',subject_name)\n",
    "        print('OBSERVER PATTERN',':',self.name,'REACTS','subject_info',subject_info)\n",
    "\n",
    "        # SETTINGS changed\n",
    "        if subject_name=='SETTINGS':\n",
    "            \n",
    "            if 'force_reload' in subject_info:\n",
    "                # told by SETTINGS to reload all backtests\n",
    "                self._data_dico.clear() # empty data_dico and reload\n",
    "                self._populate_data_dico(self._selected_backtests) # repopulate\n",
    "            else:\n",
    "                if (\n",
    "                    self._applied_backtest_path!=Path(subject_info['backtest_path']) or \n",
    "                    self._applied_view_type!=subject_info['view_type']\n",
    "                ):\n",
    "                    print('OBSERVER PATTERN',':',self.name,'clear dico')\n",
    "                    self._data_dico.clear() # empty data_dico if SETTINGS filepath OR view_type changed\n",
    "\n",
    "                # update\n",
    "                self._applied_backtest_path=subject_info['backtest_path']\n",
    "                self.reference['applied_view_type']=subject_info['view_type']\n",
    "                self.reference['applied_return_type']=subject_info['return_type']\n",
    "                self.reference['applied_date_from']=subject_info['date_from']\n",
    "                self.reference['applied_date_to']=subject_info['date_to']\n",
    "        \n",
    "        # BACKTEST_SELECTOR changed\n",
    "        if subject_name=='BACKTEST_SELECTOR':\n",
    "            self._selected_backtests=subject_info\n",
    "            self._populate_data_dico(self._selected_backtests)\n",
    "\n",
    "        # BOOK_SELECTOR changed\n",
    "        if subject_name=='BOOK_SELECTOR':\n",
    "            self._selected_books=subject_info\n",
    "\n",
    "        # logging\n",
    "        self._logging()\n",
    "        \n",
    "        # notify\n",
    "        self.notify(self.reference)\n",
    "    \n",
    "    def _populate_data_dico(self,selected_backtests) -> None:\n",
    "        # update data_dico\n",
    "        for (option_name,option_path),checked in selected_backtests.items():\n",
    "            if checked:\n",
    "                self._add_key(option_name,option_path) # make sure present\n",
    "            else:\n",
    "                self._remove_key(option_name,option_path) # make sure not present\n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    d._add_key('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    '''\n",
    "    def _add_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type : str ='dev',\n",
    "        ) -> None :\n",
    "        '''make sure data is populated'''\n",
    "        if not option_name in self._data_dico:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',option_name,'ADD')\n",
    "            self._data_dico[option_name]=pd.read_csv(self._get_filepath(option_name,option_path,view_type))\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',option_name,'pass (no add)')\n",
    "            pass\n",
    "    \n",
    "    def _remove_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        ) -> None :\n",
    "        '''make sure data removed from data_dico'''\n",
    "        if option_name in self._data_dico:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',option_name,'REMOVE')\n",
    "            del self._data_dico[option_name] # remove from dico\n",
    "        else:\n",
    "            print(self.name,':','KEYS =',len(self._data_dico),':',option_name,'pass (no remove)')\n",
    "            pass\n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='dev'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='daily'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='intraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='extraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='factor'))\n",
    "    '''\n",
    "    def _get_filepath(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type   : str ='dev',\n",
    "        ) -> Path :\n",
    "        BackestPathTuple=eval('DATA_CONTAINER.'+view_type+'()') # get BTPATHTUPLE\n",
    "        tup=[option_path.parent]+list(BackestPathTuple) # build tuple\n",
    "        tup=[option_name if x==None else x for x in tup] # overwrite None in BackestPathTuple with backtest_name\n",
    "        filepath=reduce(lambda x,y:x/y,tup) # combine into single Path object\n",
    "        filepath=Path(str(filepath) + '.csv') # append .csv suffix\n",
    "        return filepath\n",
    "        \n",
    "    def _logging(self):\n",
    "        print(self.name,':','REFERENCE',':','DATA_DICO SIZE =',len(self._data_dico))\n",
    "        for k,v in self.reference.items():\n",
    "            print(self.name,':','REFERENCE',':',k,':',v)\n",
    "\n",
    "    @classmethod\n",
    "    def dev(self) -> BTPATHTUPLE :\n",
    "        return DATA_CONTAINER._dev\n",
    "    \n",
    "    @classmethod\n",
    "    def daily(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "             extraday summary --> macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/daily/summary_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            book|pnl|stock volume|future volume|fees\n",
    "            All|.|.|.|.\n",
    "            Trading|.|.|.|.\n",
    "            Quote|.|.|.|.\n",
    "            Hedge|.|.|.|.\n",
    "\n",
    "        used to compute summary for entire backtest\n",
    "            book|return bps|sharpe|daily pnl|daily stock volume|daily future volume|fee bps\n",
    "            All|.|.|.|.|.|.\n",
    "            Trading|.|.|.|.|.|.\n",
    "            Quote|.|.|.|.|.|.\n",
    "            Hedge|.|.|.|.|.|.\n",
    "        '''\n",
    "        return DATA_CONTAINER._daily\n",
    "    \n",
    "    @classmethod\n",
    "    def extraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday behavioural analysis --> customised macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            EOD|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._extraday\n",
    "    \n",
    "    @classmethod\n",
    "    def intraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            intraday behavioural analysis --> customised macro intraday overview\n",
    "\n",
    "        dump frequency\n",
    "            n-minutely snapshots throughout the day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/intraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            10:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            10:01:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            ...\n",
    "            16:59:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            17:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._intraday\n",
    "\n",
    "    @classmethod\n",
    "    def factor(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday factor analysis --> customised macro factor analysis\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            dump on all symbols\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            Symbol|PnlTotal|PnlJour|PnlVeille|ExecNom|MedLongNom|MaxLongLongNom|MedOpenBidNom|MedOpenAskNom|...\n",
    "            sym_0|\n",
    "            sym_1|\n",
    "            ...\n",
    "            sym_n|\n",
    "        '''\n",
    "        return DATA_CONTAINER._factor\n",
    "    \n",
    "        '''\n",
    "    \n",
    "            self.raw_data=\n",
    "        self.filtered_data=self.apply_date_filters()\n",
    "        \n",
    "\n",
    "    def apply_date_filters(self):\n",
    "        # check date validity\n",
    "        \n",
    "        # remember filter dates applied\n",
    "        min_date=self.settings['date_from'].value\n",
    "        max_date=self.settings['date_to'].value\n",
    "\n",
    "        # apply date filter\n",
    "        if min_date==None and max_date==None:\n",
    "            print('no filter')\n",
    "            self.filtered_data=self.raw_data\n",
    "        elif min_date!=None and max_date==None:\n",
    "            print('filter min_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date>=min_date]\n",
    "        elif min_date==None and max_date!=None:\n",
    "            print('filter max_date')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date<=max_date]\n",
    "        else:\n",
    "            print('filter both')\n",
    "            self.filtered_data=self.raw_data[self.raw_data.Date.between(min_date,max_date)]\n",
    "            \n",
    "        # debugging\n",
    "        print(min_date)\n",
    "        print(max_date)\n",
    "        print(self.raw_data.shape)\n",
    "        print(self.filtered_data.shape)\n",
    "    '''\n",
    "\n",
    "# example\n",
    "DATA_CONTAINER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2b7c2-d297-4844-98a9-877d7a65cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "help(DATA_CONTAINER.daily)\n",
    "\n",
    "help(DATA_CONTAINER.extraday)\n",
    "\n",
    "help(DATA_CONTAINER.intraday)\n",
    "\n",
    "help(DATA_CONTAINER.factor)\n",
    "'''\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
