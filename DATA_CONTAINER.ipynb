{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b6247c-1864-40d5-aea2-3b29da9e8b77",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f601e7-4919-4936-af7e-b00fbd812f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOGGING_LEVEL') == None:\n",
    "    LOGGING_LEVEL=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d152e69-dfc3-42ea-bc8e-76b061f1c3f8",
   "metadata": {},
   "source": [
    "### module import protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa010cb6-4cfa-4737-b4f5-3334e74172a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_DATA_CONTAINER') == None:\n",
    "    if LOGGING_LEVEL > 0: print('LOADED_DATA_CONTAINER')\n",
    "    LOADED_DATA_CONTAINER=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74f8f8-5645-44f0-a8f7-11136579863c",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45993c62-1f16-4135-8bd1-597b0d82ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_ANNOTATIONS') == None:\n",
    "    %run ANNOTATIONS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784b332-0bc4-43d9-93b8-826646e8824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('LOADED_PATTERN_OBSERVER') == None:\n",
    "    %run PATTERN_OBSERVER.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c24fd-ab9c-48d3-9f6b-03ece7199868",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45c9f0a-86c8-4dc2-8e58-751ba36f1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d631a-6b89-4427-8208-115575a98ae5",
   "metadata": {},
   "source": [
    "### begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5b55e-e54b-4621-a0e4-253c1fed8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA_CONTAINER:\n",
    "    ####################################\n",
    "    # static\n",
    "    ####################################\n",
    "    # standardized file names\n",
    "    BTPATHTUPLE      = namedtuple('BTPATHTUPLE',['backtest_name','subdir','filename'])\n",
    "    _dev             = BTPATHTUPLE('./','./',None)\n",
    "    _daily           = BTPATHTUPLE(None,'./daily','summary_YYYYMMDD')\n",
    "    _extraday        = BTPATHTUPLE(None,'./extraday','BOOK_YYYYMMDD')\n",
    "    _intraday        = BTPATHTUPLE(None,'./intraday','BOOK_YYYYMMDD')\n",
    "    _factor          = BTPATHTUPLE(None,'./factor','BOOK_YYYYMMDD')\n",
    "\n",
    "    ####################################\n",
    "    # constructor\n",
    "    ####################################\n",
    "    def __init__(self,\n",
    "        name                                = 'DATA_CONTAINER',\n",
    "\n",
    "        # data\n",
    "        selected_backtests                  = None,\n",
    "        selected_books                      = None,\n",
    "\n",
    "        # reference\n",
    "        plot_method                         = None,\n",
    "        return_type                         = None,\n",
    "        view_type                           = None,\n",
    "        date_from                           = None,\n",
    "        date_to                             = None,\n",
    "        time_from                           = None,\n",
    "        time_to                             = None,\n",
    "             \n",
    "        ):\n",
    "        self._logging_level                 = LOGGING_LEVEL                  # GLOBAL VARIABLE\n",
    "        \n",
    "        self.name                           = name\n",
    "        \n",
    "        # options\n",
    "        self.reference = {\n",
    "            'selected_backtests'            : self._populate_selected_backtests(selected_backtests), # OPTIONID_VALUES\n",
    "            'selected_books'                : self._populate_selected_books(selected_books),         # OPTIONID_VALUES\n",
    "            'plot_method'                   : plot_method,                                           # str\n",
    "            'return_type'                   : return_type,                                           # str\n",
    "            'view_type'                     : view_type,                                             # str\n",
    "            'date_from'                     : date_from,                                             # DateTime.Date\n",
    "            'date_to'                       : date_to,                                               # DateTime.Date\n",
    "            'time_from'                     : time_from,                                             # DateTime.Time\n",
    "            'time_to'                       : time_to,                                               # DateTime.Time\n",
    "        }\n",
    "        \n",
    "        # building self.df\n",
    "        self.data_dico                      = {}\n",
    "        self.df                             = pd.DataFrame()\n",
    "        \n",
    "        # for observer pattern\n",
    "        self._observers                     = []\n",
    "            \n",
    "        # show internals\n",
    "        self._logging()\n",
    "        \n",
    "    ####################################\n",
    "    # populate defaults\n",
    "    ####################################\n",
    "    def _populate_selected_backtests(self,selected_backtests : OPTIONID_VALUES = None) -> OPTIONID_VALUES :\n",
    "        if selected_backtests != None:\n",
    "            return selected_backtests\n",
    "        else:\n",
    "            return {\n",
    "                ('AZUL4.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/AZUL4.SA.csv')) : True,\n",
    "                ('EMBR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/EMBR3.SA.csv')) : True,\n",
    "                ('ECOR3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/ECOR3.SA.csv')) : False,\n",
    "            }\n",
    "\n",
    "    def _populate_selected_books(self,selected_books : OPTIONID_VALUES = None) -> OPTIONID_VALUES :\n",
    "        if selected_books != None:\n",
    "            selected_books \n",
    "        else:\n",
    "            return {\n",
    "                ('Trading','Trading') : True,\n",
    "                ('Quote','Quote')     : True,\n",
    "                ('MM2','MM2')         : True,\n",
    "                ('Hedge','Hedge')     : True,\n",
    "                ('Hit','Hit')         : False,\n",
    "            }\n",
    "    \n",
    "    ####################################\n",
    "    # functions\n",
    "    ####################################\n",
    "    def build_df(self) -> None : # TODO, this needs to depend on `view_type`\n",
    "        if self._logging_level > 0: print(self.name,':','build_df')\n",
    "\n",
    "        # show internals\n",
    "        self._logging()\n",
    "        \n",
    "        ######################################################\n",
    "        # update self.data_dico\n",
    "        ######################################################\n",
    "        # add / remove entries as per checked backtests\n",
    "        for (option_name,option_path),checked in self.reference['selected_backtests'].items():\n",
    "            if checked:\n",
    "                self._data_dico_add_key(option_name,option_path) # make sure present # TODO when using real data this needs to change\n",
    "            else:\n",
    "                self._data_dico_remove_key(option_name,option_path) # make sure not present\n",
    "\n",
    "        # remove options no longer present\n",
    "        remove=[]\n",
    "        for (option_name,option_path) in self.data_dico.keys():\n",
    "            if not (option_name,option_path) in self.reference['selected_backtests'].keys():\n",
    "                remove.append((option_name,option_path))\n",
    "        \n",
    "        for (option_name,option_path) in remove:\n",
    "            self._data_dico_remove_key(option_name,option_path)\n",
    "        \n",
    "        ######################################################\n",
    "        # build self.df from self.data_dico\n",
    "        ######################################################\n",
    "        if not bool(self.data_dico):\n",
    "            # self.data_dico empty, bail\n",
    "            self.df = pd.DataFrame()\n",
    "        else:\n",
    "            # self.data_dico not empty, build df\n",
    "            \n",
    "            # flatten\n",
    "            df = pd.concat(\n",
    "                map(self._extraday_set_index,self.data_dico.values()),\n",
    "                keys  = [option_name for (option_name,option_path) in self.data_dico.keys()],\n",
    "                names = ['sym']\n",
    "            )\n",
    "\n",
    "            # reorder\n",
    "            df = df.reorder_levels([1,0])\n",
    "\n",
    "            # apply date filters\n",
    "            if self.reference['view_type'] in ['Extraday','Factor']:\n",
    "                \n",
    "                # lower date filter\n",
    "                if not self.reference['date_from'] is None:\n",
    "                    df = df[df.index.get_level_values('timestamp').date >= self.reference['date_from']]\n",
    "                    \n",
    "                # upper date filter\n",
    "                if not self.reference['date_to'] is None:\n",
    "                    df = df[df.index.get_level_values('timestamp').date <= self.reference['date_to']]\n",
    "                    \n",
    "            # apply time filters\n",
    "            if self.reference['view_type'] in ['Intraday','Factor']:\n",
    "                \n",
    "                # lower time filter\n",
    "                if not self.reference['time_from'] is None:\n",
    "                    df = df[df.index.get_level_values('timestamp').time >= self.reference['time_from']]\n",
    "                    \n",
    "                # upper time filter\n",
    "                if not self.reference['time_to'] is None:\n",
    "                    df = df[df.index.get_level_values('timestamp').time <= self.reference['time_to']]\n",
    "\n",
    "            # assign\n",
    "            self.df = df\n",
    "\n",
    "    '''set index in df for extraday view'''\n",
    "    def _extraday_set_index(self,\n",
    "        df : pd.DataFrame\n",
    "        ) -> pd.DataFrame :\n",
    "        df.timestamp = pd.to_datetime(df.timestamp)\n",
    "        return df.set_index('timestamp')\n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    d._data_dico_add_key('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    d._data_dico_add_key('VALE3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/VALE3.SA.csv'))\n",
    "    '''\n",
    "    '''make sure entry present in self.data_dico'''\n",
    "    def _data_dico_add_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type   : str = 'Dev',\n",
    "        ) -> None :\n",
    "        \n",
    "        if not (option_name,option_path) in self.data_dico:\n",
    "            self.data_dico[(option_name,option_path)] = pd.read_csv(self._get_filepath(option_name,option_path,view_type))\n",
    "            if self._logging_level > 1: print(self.name,':','KEYS =',len(self.data_dico),':',(option_name,option_path),'ADD')\n",
    "        else:\n",
    "            if self._logging_level > 1: print(self.name,':','KEYS =',len(self.data_dico),':',(option_name,option_path),'pass (no add)')\n",
    "            pass\n",
    "    \n",
    "    '''make sure data NOT present in self.data_dico'''\n",
    "    def _data_dico_remove_key(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        ) -> None :\n",
    "        if (option_name,option_path) in self.data_dico:\n",
    "            del self.data_dico[(option_name,option_path)]\n",
    "            if self._logging_level > 1: print(self.name,':','KEYS =',len(self.data_dico),':',(option_name,option_path),'REMOVE')\n",
    "        else:\n",
    "            if self._logging_level > 1: print(self.name,':','KEYS =',len(self.data_dico),':',(option_name,option_path),'pass (no remove)')\n",
    "            pass\n",
    "\n",
    "    '''\n",
    "    d=DATA_CONTAINER()\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='Dev'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='Daily'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='Intraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='Extraday'))\n",
    "    print(d._get_filepath('BRFS3.SA',Path(r'C:/Users/ahkar/OneDrive/Documents/Data/B3/BRFS3.SA.csv'),view_type='Factor'))\n",
    "    '''\n",
    "    def _get_filepath(self,\n",
    "        option_name : str,\n",
    "        option_path : Path,\n",
    "        view_type   : str = 'Dev'\n",
    "        ) -> Path :\n",
    "        print(self.name,':','_get_filepath',option_name,option_path,view_type)\n",
    "\n",
    "        # build filepath\n",
    "        BackestPathTuple = eval('DATA_CONTAINER.'+view_type+'()')          # get BTPATHTUPLE via class methods calls\n",
    "        tup              = [option_path.parent]+list(BackestPathTuple)     # build tuple\n",
    "        tup              = [option_name if x==None else x for x in tup]    # overwrite None in BackestPathTuple with backtest_name\n",
    "        filepath         = reduce(lambda x,y:x/y,tup)                      # combine into single Path object\n",
    "        filepath         = Path(str(filepath) + '.csv')                    # append .csv suffix\n",
    "        \n",
    "        # return\n",
    "        return filepath\n",
    "        \n",
    "    def _logging(self):\n",
    "        if self._logging_level > 0: print(self.name,':','REFERENCE',':','LEN(DATA_DICO) =',len(self.data_dico),'LEN(DF) =',len(self.df))\n",
    "        for k,v in self.reference.items():\n",
    "            if self._logging_level > 1: print(self.name,':','REFERENCE',':',k,':',v)\n",
    "        \n",
    "    @classmethod\n",
    "    def Dev(self) -> BTPATHTUPLE :\n",
    "        return DATA_CONTAINER._dev\n",
    "    \n",
    "    @classmethod\n",
    "    def Daily(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "             extraday summary --> macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/daily/summary_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            book|pnl|stock volume|future volume|fees\n",
    "            All|.|.|.|.\n",
    "            Trading|.|.|.|.\n",
    "            Quote|.|.|.|.\n",
    "            Hedge|.|.|.|.\n",
    "\n",
    "        used to compute summary for entire backtest\n",
    "            book|return bps|sharpe|daily pnl|daily stock volume|daily future volume|fee bps\n",
    "            All|.|.|.|.|.|.\n",
    "            Trading|.|.|.|.|.|.\n",
    "            Quote|.|.|.|.|.|.\n",
    "            Hedge|.|.|.|.|.|.\n",
    "        '''\n",
    "        return DATA_CONTAINER._daily\n",
    "    \n",
    "    @classmethod\n",
    "    def Extraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday behavioural analysis --> customised macro extraday overview\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            EOD|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._extraday\n",
    "    \n",
    "    @classmethod\n",
    "    def Intraday(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            intraday behavioural analysis --> customised macro intraday overview\n",
    "\n",
    "        dump frequency\n",
    "            n-minutely snapshots throughout the day\n",
    "            reference symbol `Symbol` is used to initialize the dump\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/intraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/intraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            TimeStamp|Symbol|PnlTotal|PnlJour|PnlVeille|OpenNom|OpenBidNom|OpenAskNom|...\n",
    "            10:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            10:01:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            ...\n",
    "            16:59:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "            17:00:00|VALE3.SA|.|.|.|.|.|.|...\n",
    "        '''\n",
    "        return DATA_CONTAINER._intraday\n",
    "\n",
    "    def Factor(self) -> BTPATHTUPLE :\n",
    "        '''\n",
    "        purpose\n",
    "            extraday factor analysis --> customised macro factor analysis\n",
    "\n",
    "        dump frequency\n",
    "            once a day at end of day\n",
    "            dump on all symbols\n",
    "\n",
    "        example files\n",
    "            ./backtest_name/extraday/Trading_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Quote_yyyymmdd.csv\n",
    "            ./backtest_name/extraday/Hedge_yyyymmdd.csv\n",
    "\n",
    "        contents of each daily file\n",
    "            Symbol|PnlTotal|PnlJour|PnlVeille|ExecNom|MedLongNom|MaxLongLongNom|MedOpenBidNom|MedOpenAskNom|...\n",
    "            sym_0|\n",
    "            sym_1|\n",
    "            ...\n",
    "            sym_n|\n",
    "        '''\n",
    "        return DATA_CONTAINER._factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2b848-ab7a-48ed-a22e-55ea4c283f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __file__ exists if notebook called with %run but doesnt it called manually\n",
    "# e.g. I only wish to run the example when calling this notebook directly\n",
    "try:\n",
    "    __file__\n",
    "except NameError:\n",
    "    # example\n",
    "    a=DATA_CONTAINER()\n",
    "    display(dir(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2b7c2-d297-4844-98a9-877d7a65cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "help(DATA_CONTAINER.daily)\n",
    "\n",
    "help(DATA_CONTAINER.extraday)\n",
    "\n",
    "help(DATA_CONTAINER.intraday)\n",
    "\n",
    "help(DATA_CONTAINER.factor)\n",
    "'''\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
